{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-16T00:16:45.979822Z","iopub.execute_input":"2024-10-16T00:16:45.980979Z","iopub.status.idle":"2024-10-16T00:16:58.372283Z","shell.execute_reply.started":"2024-10-16T00:16:45.980920Z","shell.execute_reply":"2024-10-16T00:16:58.371096Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\n\nurl = \"https://drive.google.com/file/d/1oP4ktwKPC7s4l_drptKiC1cERTAmjjPp/view?usp=sharing\"\n\nout = \"acllmdb.zip\"\n\n# Download the file in google drive using Python\ngdown.download(url, out, quiet=False,fuzzy=True)\n\n# Download a folder in google drive using Python\n# gdown.download_folder(url, quiet=True, use_cookies=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T00:16:58.375207Z","iopub.execute_input":"2024-10-16T00:16:58.375731Z","iopub.status.idle":"2024-10-16T00:17:02.493520Z","shell.execute_reply.started":"2024-10-16T00:16:58.375674Z","shell.execute_reply":"2024-10-16T00:17:02.492515Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1oP4ktwKPC7s4l_drptKiC1cERTAmjjPp\nFrom (redirected): https://drive.google.com/uc?id=1oP4ktwKPC7s4l_drptKiC1cERTAmjjPp&confirm=t&uuid=b46a242f-26c6-4ef1-ba82-46c6e39175b0\nTo: /kaggle/working/acllmdb.zip\n100%|██████████| 42.8M/42.8M [00:01<00:00, 26.8MB/s]\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'acllmdb.zip'"},"metadata":{}}]},{"cell_type":"code","source":"import zipfile\nzip_ref = zipfile.ZipFile(\"/kaggle/working/acllmdb.zip\", 'r')\nzip_ref.extractall(\"/kaggle/working/\")\nzip_ref.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T00:17:02.494742Z","iopub.execute_input":"2024-10-16T00:17:02.495186Z","iopub.status.idle":"2024-10-16T00:17:09.046818Z","shell.execute_reply.started":"2024-10-16T00:17:02.495151Z","shell.execute_reply":"2024-10-16T00:17:09.045635Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# utils\nimport os\nimport random\nimport numpy as np\nimport shutil\n\ndef clear_folder(folder):\n    for filename in os.listdir(folder):\n        file_path = os.path.join(folder, filename)\n        try:\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print('Failed to delete %s. Reason: %s' % (file_path, e))\n\ndef remove(path):\n    os.remove(path)\n    \n# make archieve\ndef make_zip(\n        output_filename = \"/kaggle/working/images28\",\n        dir_name = \"/kaggle/working/images\"\n):\n    shutil.make_archive(output_filename, 'zip', dir_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:12:39.300574Z","iopub.execute_input":"2024-10-16T19:12:39.301336Z","iopub.status.idle":"2024-10-16T19:12:39.314528Z","shell.execute_reply.started":"2024-10-16T19:12:39.301284Z","shell.execute_reply":"2024-10-16T19:12:39.313613Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"make_zip(dir_name=\"/kaggle/working/dataset\", output_filename=\"/kaggle/working/dataset\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T00:23:01.523006Z","iopub.execute_input":"2024-10-16T00:23:01.524079Z","iopub.status.idle":"2024-10-16T00:23:10.507263Z","shell.execute_reply.started":"2024-10-16T00:23:01.524029Z","shell.execute_reply":"2024-10-16T00:23:10.506192Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\n\ndef preprocess_text(text):\n    new_text = text.lower().replace('<br />', '')\n    \n    new_text = re.sub(\"[%s]\" % re.escape(string.punctuation), '', new_text)\n    \n    return new_text\n\ntest = \"This may not be a memorable classic, but it is a touching romance with an important theme that stresses the importance of literacy in modern society and the devastating career and life consequences for any unfortunate individual lacking this vital skill.<br /><br />The story revolves around Iris, a widow who becomes acquainted with a fellow employee at her factory job, an illiterate cafeteria worker named Stanley. Iris discovers that Stanley is unable to read, and after he loses his job, she gives him reading lessons at home in her kitchen. Of course, as you might predict, the two, although initially wary of involvement, develop feelings for each other...<br /><br />Jane Fonda competently plays Iris, a woman with problems of her own, coping with a job lacking prospects, two teenage children (one pregnant), an unemployed sister and her abusive husband. However, Robert DeNiro is of course brilliant in his endearing portrayal of the intelligent and resourceful, but illiterate, Stanley, bringing a dignity to the role that commands respect. They aren't your typical charming young yuppie couple, as generally depicted in on screen romances, but an ordinary working class, middle aged pair with pretty down to earth struggles.<br /><br />I won't give the ending away, but it's a lovely, heartwarming romance and a personal look into the troubling issue of adult illiteracy, albeit from the perspective of a fictional character.\"\n\n_test = preprocess_text(test)\n\nprint(_test)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_string = \"pos_12.txt\"\npattern = r\"(?<=\\_)\\d+(?=\\.txt)\"\n\nresult = re.search(pattern, target_string, re.M)\n\nprint(result.group())","metadata":{"execution":{"iopub.status.busy":"2024-10-16T00:16:21.468654Z","iopub.execute_input":"2024-10-16T00:16:21.469035Z","iopub.status.idle":"2024-10-16T00:16:21.474665Z","shell.execute_reply.started":"2024-10-16T00:16:21.469000Z","shell.execute_reply":"2024-10-16T00:16:21.473452Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"12\n","output_type":"stream"}]},{"cell_type":"code","source":"from gensim.models import FastText\nfrom gensim.test.utils import common_texts\n\n# Example corpus (replace with your own corpus)\ncorpus = common_texts\n\n# Training FastText model\nfastText = FastText(sentences=corpus, vector_size=256, window=5, min_count=1, workers=4, sg=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:18:07.618407Z","iopub.execute_input":"2024-10-16T17:18:07.618799Z","iopub.status.idle":"2024-10-16T17:18:19.195623Z","shell.execute_reply.started":"2024-10-16T17:18:07.618761Z","shell.execute_reply":"2024-10-16T17:18:19.194688Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import re\nfrom torch.utils.data import Dataset, DataLoader\nimport string\nfrom transformers import AlbertTokenizer, AlbertModel\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef preprocess_text(text):\n    new_text = text.lower().replace('<br />', '')\n    \n    new_text = re.sub(\"[%s]\" % re.escape(string.punctuation), '', new_text)\n    \n    return new_text\n\n\ndef preprocess_bert(text):\n    new_text = text.lower().replace('<br />', '')\n    \n    new_text = re.sub(\"[%s]\" % re.escape(string.punctuation), '', new_text)\n    \n    new_text = f\"[CLS] {new_text}[SEP]\"\n    \n    return new_text\n\n\ndef get_embeddings(text):\n    # Example usage: getting embeddings for a word\n    word_embedding = fastText.wv[text]\n    return word_embedding\n\n\nclass Vectorizer(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n        self.model = AlbertModel.from_pretrained('albert-base-v2').to(device)\n        \n        for param in self.model.parameters():\n            param.requires_grad = False\n\n    \n    def forward(self, text):\n        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n        \n        inputs = {key: value.to(device) for key, value in inputs.items()}\n\n        outputs = self.model(**inputs)\n        \n        last_hidden_state = outputs.last_hidden_state  # Размер [batch_size, seq_len, hidden_size]\n\n        # Маска внимания, чтобы исключить `<PAD>` токены\n        attention_mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden_state.size()).float()\n\n        # Вычисление средних эмбеддингов для каждого предложения\n        sum_embeddings = torch.sum(last_hidden_state * attention_mask, dim=1)\n        sum_mask = torch.clamp(attention_mask.sum(dim=1), min=1e-9)  # Чтобы избежать деления на ноль\n        mean_pooled = sum_embeddings / sum_mask\n\n        return mean_pooled.view(-1)    \n\n\ndef get_all_txt(dir_path):\n    paths = []\n    pattern = r\"(?<=\\_)\\d+(?=\\.txt)\"\n    \n    for file_path in os.listdir(dir_path):\n        # check if current file_path is a file\n        file = os.path.join(dir_path, file_path)\n        result = re.search(pattern, file_path)\n        \n        if os.path.isfile(file) and result is not None:\n\n            paths.append(file)\n    \n    return paths\n\nvectorizer = Vectorizer().to(device)\n\nfrom sklearn.model_selection import train_test_split\n\nclass BaseDataset(Dataset):\n    def __init__(self, dir_path, transform_text):\n        paths = get_all_txt(dir_path)\n        \n        self.paths, _ = train_test_split(paths, test_size=0.3, random_state=42)\n        \n        self.transform = transform_text\n        self.pattern = r\"(?<=\\_)\\d+(?=\\.txt)\"\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        path = self.paths[idx]\n        \n        result = re.search(self.pattern, path)\n\n        label = int(result.group()) - 1\n        \n        if label > 3:\n            label -= 2\n\n        with open(path, \"r\") as f:\n            text = f.read()\n            \n        text = self.transform(text)\n        \n#         sample = get_embeddings(text)\n        \n# #         sample = torch.mean(sample, dim=1).view(-1)\n        \n#         y = torch.tensor(label, dtype=torch.long, device = sample.device)\n        \n        return text, label\n    \n\nclass TextDataset(Dataset):\n    def __init__(self, dir_path, transform_text):\n        self.paths = get_all_txt(dir_path)\n        self.transform = transform_text\n        self.pattern = r\"(?<=\\_)\\d+(?=\\.txt)\"\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        path = self.paths[idx]\n        \n        result = re.search(self.pattern, path)\n\n        label = int(result.group()) - 1\n        \n        if label > 3:\n            label -= 2\n\n        with open(path, \"r\") as f:\n            text = f.read()\n            \n        text = self.transform(text)\n        \n        sample = get_embeddings(text)\n        \n# #         sample = torch.mean(sample, dim=1).view(-1)\n        \n#         y = torch.tensor(label, dtype=torch.long, device = sample.device)\n        \n        return sample, label\n    \n    \ndef create_dataloader(dir_path, transform_text, batch_size, shuffle=False, pin_memory=False):\n\n#     dataset = TextDataset(dir_path, transform_text)\n    \n    dataset = BaseDataset(dir_path, transform_text)\n    \n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=pin_memory)\n    \n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:13:18.961896Z","iopub.execute_input":"2024-10-16T19:13:18.962568Z","iopub.status.idle":"2024-10-16T19:13:23.108230Z","shell.execute_reply.started":"2024-10-16T19:13:18.962530Z","shell.execute_reply":"2024-10-16T19:13:23.106869Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Предположим, что у вас уже есть датасет\n\ndir_path = \"/kaggle/working/dataset/test\"\n\ndataset = BaseDataset(dir_path, preprocess_text)\n\n# Используем DataLoader для итерации по датасету\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n\n# Инициализируем переменные для хранения min и max значений\nmin_val = torch.inf\nmax_val = -torch.inf\n\n# Проходим по всем батчам датасета\nfor batch in dataloader:\n    _, inputs = batch  # inputs - это ваши векторные данные\n\n    # Находим минимум и максимум в текущем батче\n    batch_min = inputs.min()\n    batch_max = inputs.max()\n\n    # Обновляем общий минимум и максимум\n    min_val = min(min_val, batch_min.item())\n    max_val = max(max_val, batch_max.item())\n\n# Выводим найденные значения\nprint(f\"Minimum value in dataset: {min_val}\")\nprint(f\"Maximum value in dataset: {max_val}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:19:55.633153Z","iopub.execute_input":"2024-10-16T17:19:55.633773Z","iopub.status.idle":"2024-10-16T17:19:57.334408Z","shell.execute_reply.started":"2024-10-16T17:19:55.633728Z","shell.execute_reply":"2024-10-16T17:19:57.333479Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Minimum value in dataset: 0\nMaximum value in dataset: 7\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AlbertTokenizer, AlbertModel\n\n# Загрузка модели ALBERT\ntokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\nmodel = AlbertModel.from_pretrained('albert-base-v2')\n\n# Пример текста\ntext = \"I love programming in Python I love programming in Python\"\ninputs = tokenizer(_test, return_tensors=\"pt\")\noutputs = model(**inputs)\n\n# Получение эмбеддингов\nlast_hidden_states = outputs.last_hidden_state\nprint(last_hidden_states.shape)\n\nimport torch\n\nres = torch.mean(last_hidden_states, dim=(1))\n\nprint(res.shape)\n\n# torch.Size([1, 247, 768])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T01:09:51.875449Z","iopub.execute_input":"2024-10-16T01:09:51.876224Z","iopub.status.idle":"2024-10-16T01:09:53.208132Z","shell.execute_reply.started":"2024-10-16T01:09:51.876181Z","shell.execute_reply":"2024-10-16T01:09:53.206998Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"torch.Size([1, 247, 768])\ntorch.Size([1, 768])\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gensim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import FastText\nfrom gensim.test.utils import common_texts\n\n# Example corpus (replace with your own corpus)\ncorpus = common_texts\n\n# Training FastText model\nmodel = FastText(sentences=corpus, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n\n# Example usage: getting embeddings for a word\nword_embedding = model.wv['computer']\n\nprint(word_embedding)\n\n# # Most similar words to a given word\n# similar_words = model.wv.most_similar('computer')\n\n# print(\"Most similar words to 'computer':\", similar_words)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:24:25.890003Z","iopub.execute_input":"2024-10-16T12:24:25.890395Z","iopub.status.idle":"2024-10-16T12:24:26.980436Z","shell.execute_reply.started":"2024-10-16T12:24:25.890359Z","shell.execute_reply":"2024-10-16T12:24:26.979307Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[ 2.9685666e-04  3.3072010e-04 -8.7743282e-04  3.3974674e-04\n -5.0194800e-04 -2.0421152e-03 -1.2409585e-03 -1.9403716e-03\n  1.3458645e-03 -2.4129902e-03  9.1810629e-04 -1.0314244e-03\n -7.6350034e-04  7.3201641e-05  1.3831169e-03  5.1904464e-04\n -2.9898007e-04 -1.1948631e-03 -1.1725607e-03 -6.0877239e-04\n -6.7762885e-04  3.9272508e-04  9.8973374e-05  8.1221922e-04\n  5.8214430e-04  7.0246187e-04 -7.3612190e-04 -1.0396213e-03\n -6.2489061e-04 -2.4085796e-04 -1.1932147e-03 -2.6620671e-04\n  7.3646189e-04 -7.2184735e-04 -1.2750521e-03  1.2425568e-04\n  3.7789033e-04 -1.3312516e-03 -2.7341598e-03 -3.0504598e-04\n  9.2881807e-04 -7.2819379e-04 -1.1289539e-03 -3.2218394e-04\n -2.0561849e-04 -1.0497047e-04 -6.2273885e-04 -1.6138694e-03\n  9.9103095e-04  9.2174501e-05  3.6866101e-04 -5.3755875e-04\n  1.1334866e-03  8.7075913e-04 -1.6392255e-03 -8.5598481e-04\n -6.3172285e-04  6.2362582e-04  8.4005587e-04 -1.1280770e-03\n  1.2912388e-03 -3.4063371e-04 -1.1784503e-03 -1.6083722e-03\n  1.5276625e-03  3.0762585e-05 -2.3881905e-05 -7.2689116e-04\n  1.7333305e-03  8.9337263e-04  3.2672373e-04 -4.6351869e-04\n -2.3139569e-03 -1.7195115e-03  4.3598001e-04 -4.1184871e-04\n -1.0671236e-03 -1.0088253e-03 -1.6432530e-03 -1.0512238e-04\n  1.0194875e-03 -6.2446174e-04 -1.0817207e-03  8.8520825e-04\n -1.4574496e-03  6.4815575e-04  4.4149806e-04 -1.2449403e-03\n  3.4934352e-04 -9.8154694e-04 -9.7427930e-04 -1.9841650e-04\n -1.8970364e-04 -9.8524254e-04  5.7457137e-04  1.9907474e-03\n  7.2554438e-05  9.9574542e-04 -1.7084853e-03  1.3490210e-03]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\n\n# Загрузка модели TinyBERT\ntokenizer = BertTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\nmodel = BertModel.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n\n# Пример текста\ntext = \"I love programming in Python\"\ninputs = tokenizer(_test, return_tensors=\"pt\")\noutputs = model(**inputs)\n\n# Получение эмбеддингов\nlast_hidden_states = outputs.last_hidden_state\nprint(last_hidden_states.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T00:43:59.144032Z","iopub.execute_input":"2024-10-16T00:43:59.144593Z","iopub.status.idle":"2024-10-16T00:44:03.016659Z","shell.execute_reply.started":"2024-10-16T00:43:59.144554Z","shell.execute_reply":"2024-10-16T00:44:03.015594Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d5dfe60f644817bf6397f6f5f3b37b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d8fc7ca546d4aeb9a1642e8502b8ca3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc74ffa985c94eb2ab13f58eef6f3fe9"}},"metadata":{}},{"name":"stdout","text":"torch.Size([1, 248, 312])\n","output_type":"stream"}]},{"cell_type":"code","source":"def save_model(model, path, name=\"reviewer\"):\n    torch.save(model.state_dict(), f\"{path}/{name}.model\")\n\ndef load_model(model, path, name=\"reviewer\"):\n    model.load_state_dict(torch.load(f\"{path}/{name}.model\", weights_only=True))\n\n    model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:13:35.810209Z","iopub.execute_input":"2024-10-16T19:13:35.810999Z","iopub.status.idle":"2024-10-16T19:13:35.816380Z","shell.execute_reply.started":"2024-10-16T19:13:35.810959Z","shell.execute_reply":"2024-10-16T19:13:35.815357Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\n\nclass MovieReviewer(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.num_classes = 8\n        self.vector_size = 256\n        self.hidden_features_0 = 512\n        self.hidden_features_1 = 128\n        \n        self.model = nn.Sequential(*[\n            nn.Linear(self.vector_size, self.hidden_features_0),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(self.hidden_features_0, self.hidden_features_1),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(self.hidden_features_1, self.num_classes)\n        ])\n        \n    def forward(self, x):\n        # x.shape = torch.Size([b, 768])\n        \n        x = self.model(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:20:42.561567Z","iopub.execute_input":"2024-10-16T17:20:42.561953Z","iopub.status.idle":"2024-10-16T17:20:42.569584Z","shell.execute_reply.started":"2024-10-16T17:20:42.561917Z","shell.execute_reply":"2024-10-16T17:20:42.568713Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torchinfo\n\nreviewer = MovieReviewer()\n\ntorchinfo.summary(reviewer, input_size=(1, 256), col_names = (\"input_size\", \"output_size\", \"num_params\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:20:46.699612Z","iopub.execute_input":"2024-10-16T17:20:46.700456Z","iopub.status.idle":"2024-10-16T17:20:46.840874Z","shell.execute_reply.started":"2024-10-16T17:20:46.700414Z","shell.execute_reply":"2024-10-16T17:20:46.839900Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"===================================================================================================================\nLayer (type:depth-idx)                   Input Shape               Output Shape              Param #\n===================================================================================================================\nMovieReviewer                            [1, 256]                  [1, 8]                    --\n├─Sequential: 1-1                        [1, 256]                  [1, 8]                    --\n│    └─Linear: 2-1                       [1, 256]                  [1, 512]                  131,584\n│    └─ReLU: 2-2                         [1, 512]                  [1, 512]                  --\n│    └─Dropout: 2-3                      [1, 512]                  [1, 512]                  --\n│    └─Linear: 2-4                       [1, 512]                  [1, 128]                  65,664\n│    └─ReLU: 2-5                         [1, 128]                  [1, 128]                  --\n│    └─Dropout: 2-6                      [1, 128]                  [1, 128]                  --\n│    └─Linear: 2-7                       [1, 128]                  [1, 8]                    1,032\n===================================================================================================================\nTotal params: 198,280\nTrainable params: 198,280\nNon-trainable params: 0\nTotal mult-adds (M): 0.20\n===================================================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.79\nEstimated Total Size (MB): 0.80\n==================================================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n    def __init__(self):\n        super(BertClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        \n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n        # Добавляем полносвязный классификатор\n        self.classifier = nn.Linear(self.bert.config.hidden_size, 8)  # Предположим, задача классификации на 2 класса\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs[1]  # Получаем эмбеддинг для [CLS] токена\n        logits = self.classifier(pooled_output)\n        return logits","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nbatch_size = 128\n\n\ndef main():\n    \n    model = MovieReviewer()\n\n    model.to(device)\n\n    for module in model.modules():\n        if isinstance(module, nn.Linear):\n            nn.init.normal_(module.weight, 0.0, 0.02)\n            if module.bias is not None:\n                nn.init.constant_(module.bias, 0)\n    #     if (isinstance(module, nn.BatchNorm2d)):\n    #         nn.init.normal_(module.weight, 1.0, 0.02)\n    #         if module.bias is not None:\n    #             nn.init.constant_(module.bias, 0)\n    #     if (isinstance(module, nn.Embedding)):\n    #         nn.init.uniform_(module.weight, -0.1, 0.1)\n\n    train_loader = create_dataloader(\"/kaggle/working/dataset/train\", preprocess_text, batch_size, shuffle=True, pin_memory=False)\n    test_loader = create_dataloader(\"/kaggle/working/dataset/test\", preprocess_text, batch_size, shuffle=False, pin_memory=False)\n\n    \n    num_epochs = 10\n    \n    # Определение оптимизатора и функции потерь\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n\n    def train_one_epoch(epoch):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n        \n        for batch_idx, (text, target) in loop:\n            text = text.to(device)\n            target = target.to(device)\n            \n            optimizer.zero_grad()\n\n            outputs = model(text)\n\n            loss = criterion(outputs, target)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * text.size(0)\n            _, predicted = torch.max(outputs, 1)\n            \n            correct += (predicted == target).sum().item()\n            total += text.size(0)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_accuracy = correct / total\n\n        print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n\n        save_model(model, \"/kaggle/working/\")\n\n    \n    def evaluate(epoch):\n        model.eval()\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            loop = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n            for bathc_idx, (text, target) in loop:\n                text = text.to(device)\n                target = target.to(device)\n\n                outputs = model(text)\n\n                _, predicted = torch.max(outputs, 1)\n                \n                correct += (predicted == target).sum().item()\n                total += text.size(0)\n        \n        accuracy = correct / total\n\n        print(f'Test Accuracy: {accuracy:.4f}')\n\n    \n    for epoch in range(num_epochs):\n        train_one_epoch(epoch)\n        evaluate(epoch)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:44:31.373013Z","iopub.execute_input":"2024-10-16T17:44:31.373834Z","iopub.status.idle":"2024-10-16T17:44:31.389913Z","shell.execute_reply.started":"2024-10-16T17:44:31.373793Z","shell.execute_reply":"2024-10-16T17:44:31.389015Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:44:38.186177Z","iopub.execute_input":"2024-10-16T17:44:38.186540Z","iopub.status.idle":"2024-10-16T17:56:38.211189Z","shell.execute_reply.started":"2024-10-16T17:44:38.186503Z","shell.execute_reply":"2024-10-16T17:56:38.209800Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 2.0607, Accuracy: 0.2034\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.2009\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 2.0270, Accuracy: 0.2040\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.2009\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 95\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     evaluate(epoch)\n","Cell \u001b[0;32mIn[16], line 45\u001b[0m, in \u001b[0;36mmain.<locals>.train_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (text, target) \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[1;32m     46\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[6], line 144\u001b[0m, in \u001b[0;36mTextDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    140\u001b[0m             text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    142\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(text)\n\u001b[0;32m--> 144\u001b[0m         sample \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# #         sample = torch.mean(sample, dim=1).view(-1)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m         \n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#         y = torch.tensor(label, dtype=torch.long, device = sample.device)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m sample, label\n","Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(text):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Example usage: getting embeddings for a word\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     word_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mfastText\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word_embedding\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/fasttext.py:1113\u001b[0m, in \u001b[0;36mFastTextKeyedVectors.get_vector\u001b[0;34m(self, word, norm)\u001b[0m\n\u001b[1;32m   1111\u001b[0m word_vec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors_ngrams\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m   1112\u001b[0m ngram_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors_ngrams\n\u001b[0;32m-> 1113\u001b[0m ngram_hashes \u001b[38;5;241m=\u001b[39m \u001b[43mft_ngram_hashes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ngram_hashes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;66;03m# If it is impossible to extract _any_ ngrams from the input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# https://github.com/RaRe-Technologies/gensim/issues/2402\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not extract any ngrams from \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, returning origin vector\u001b[39m\u001b[38;5;124m'\u001b[39m, word)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/fasttext.py:1345\u001b[0m, in \u001b[0;36mft_ngram_hashes\u001b[0;34m(word, minn, maxn, num_buckets)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mft_ngram_hashes\u001b[39m(word, minn, maxn, num_buckets):\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the ngrams of the word and hash them.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m \n\u001b[1;32m   1329\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \n\u001b[1;32m   1344\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1345\u001b[0m     encoded_ngrams \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ngrams_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m     hashes \u001b[38;5;241m=\u001b[39m [ft_hash_bytes(n) \u001b[38;5;241m%\u001b[39m num_buckets \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m encoded_ngrams]\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hashes\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom transformers import BertTokenizer, BertModel\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs = 10\n\nclass BertClassifier(nn.Module):\n    def __init__(self, num_classes=8):\n        super(BertClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased') #'prajjwal1/bert-tiny')\n        \n        for param in self.bert.parameters():\n            param.requires_grad = False\n        \n        self.relu = nn.ReLU()\n        \n        # Линейный слой для уменьшения размерности\n        self.l1 = nn.Linear(self.bert.config.hidden_size, 64)\n        \n        # GRU слой с размером hidden state 100 и 10 слоями\n        self.gru = nn.GRU(64, 100, num_layers=10, batch_first=True)\n        \n        # Финальный линейный слой для классификации\n        self.out = nn.Linear(100, num_classes)\n        \n\n    def forward(self, input_ids, attention_mask):\n\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n    \n        pooled_output = outputs.last_hidden_state  # [batch_size, sequence_length, hidden_size]\n        \n        # Применяем линейный слой и ReLU\n        x = self.relu(self.l1(pooled_output))  # [batch_size, sequence_length, 64]\n        \n        # Пропускаем через GRU слой\n        gru_output, _ = self.gru(x)  # [batch_size, sequence_length, 100]\n        \n        # Используем последний hidden state (последний токен)\n        gru_last_hidden = gru_output[:, -1, :]  # [batch_size, 100]\n        \n        # Финальная классификация через линейный слой\n        logits = self.out(gru_last_hidden) \n        \n        return logits\n\n# Функция для обучения одной эпохи\ndef train_one_epoch(epoch, model, train_loader, optimizer, scheduler, criterion):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    loop = tqdm(enumerate(train_loader), total=len(train_loader))\n    loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n    \n    for batch_idx, (text, target) in loop:\n        # Токенизация и подготовка данных\n        inputs = tokenizer(text, \n                           return_tensors=\"pt\", \n                           max_length=512, \n                           truncation=True, \n                           padding=True,\n                          return_attention_mask=True).to(device)\n        \n        input_ids = inputs['input_ids'].to(device)\n        attention_mask = inputs['attention_mask'].to(device)\n        target = target.to(device)\n\n        optimizer.zero_grad()\n        \n        # Прямой проход\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        \n        # Используем CrossEntropy Loss (не требуется one-hot encoding)\n        loss = criterion(outputs, target)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * len(text)\n        _, predicted = torch.max(outputs, 1)\n\n        correct += (predicted == target).sum().item()\n        total += len(text)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    epoch_accuracy = correct / total\n    \n    scheduler.step(epoch_loss)\n\n    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n\n# Пример использования\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased') #'prajjwal1/bert-tiny')\nmodel = BertClassifier().to(device)\n\ntrain_loader = create_dataloader(\"/kaggle/working/dataset/train\", preprocess_text, batch_size, shuffle=True, pin_memory=False)\ntest_loader = create_dataloader(\"/kaggle/working/dataset/test\", preprocess_text, batch_size, shuffle=False, pin_memory=False)\n\n\n# Оптимизатор и критерий\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=False)\ncriterion = nn.CrossEntropyLoss()\n\n\nfor i in range(10):\n    # Вызов функции для тренировки одной эпохи\n    train_one_epoch(i, model, train_loader, optimizer, scheduler, criterion)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:09:08.692640Z","iopub.execute_input":"2024-10-16T18:09:08.693063Z","iopub.status.idle":"2024-10-16T19:10:05.649595Z","shell.execute_reply.started":"2024-10-16T18:09:08.693025Z","shell.execute_reply":"2024-10-16T19:10:05.647859Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Epoch [1/10]: 100%|██████████| 137/137 [07:27<00:00,  3.26s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 2.0032, Accuracy: 0.2277\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/10]: 100%|██████████| 137/137 [07:28<00:00,  3.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 1.7977, Accuracy: 0.3274\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/10]: 100%|██████████| 137/137 [07:28<00:00,  3.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 1.7293, Accuracy: 0.3394\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/10]: 100%|██████████| 137/137 [07:29<00:00,  3.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 1.6738, Accuracy: 0.3511\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/10]: 100%|██████████| 137/137 [07:29<00:00,  3.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 1.6194, Accuracy: 0.3611\n","output_type":"stream"},{"name":"stderr","text":"Epoch [6/10]: 100%|██████████| 137/137 [07:29<00:00,  3.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 1.6145, Accuracy: 0.3643\n","output_type":"stream"},{"name":"stderr","text":"Epoch [7/10]: 100%|██████████| 137/137 [07:29<00:00,  3.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 1.5941, Accuracy: 0.3712\n","output_type":"stream"},{"name":"stderr","text":"Epoch [8/10]: 100%|██████████| 137/137 [07:29<00:00,  3.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 1.5786, Accuracy: 0.3742\n","output_type":"stream"},{"name":"stderr","text":"Epoch [9/10]:  14%|█▍        | 19/137 [01:02<06:31,  3.32s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 114\u001b[0m\n\u001b[1;32m    109\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Вызов функции для тренировки одной эпохи\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[23], line 64\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, train_loader, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m     60\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (text, target) \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Токенизация и подготовка данных\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     71\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     72\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3024\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3024\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3112\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3107\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3108\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3109\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3110\u001b[0m         )\n\u001b[1;32m   3111\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3135\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3136\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3154\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3155\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3314\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3304\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3305\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3306\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3307\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3311\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3312\u001b[0m )\n\u001b[0;32m-> 3314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils.py:885\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    883\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 885\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    886\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils.py:852\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 852\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils.py:695\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    696\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:161\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[0;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[1;32m    159\u001b[0m split_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_basic_tokenize:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnever_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# If the token is part of the never_split set\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_tokenizer\u001b[38;5;241m.\u001b[39mnever_split:\n\u001b[1;32m    166\u001b[0m             split_tokens\u001b[38;5;241m.\u001b[39mappend(token)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:358\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    356\u001b[0m     token \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_accents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_strip_accents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_accents:\n\u001b[1;32m    360\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_strip_accents(token)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:375\u001b[0m, in \u001b[0;36mBasicTokenizer._run_strip_accents\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(char)\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"save_model(model, path=\"/kaggle/working/\", name=\"bert_cl\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:10:14.129047Z","iopub.execute_input":"2024-10-16T19:10:14.129431Z","iopub.status.idle":"2024-10-16T19:10:14.772487Z","shell.execute_reply.started":"2024-10-16T19:10:14.129392Z","shell.execute_reply":"2024-10-16T19:10:14.771716Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom transformers import AutoTokenizer, AlbertForSequenceClassification\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs = 10\nbatch_size = 32\n\nmodel = AlbertForSequenceClassification.from_pretrained(\n                                                    \"textattack/albert-base-v2-imdb\", \n                                                      num_labels=8, ignore_mismatched_sizes=True,\n                                                     problem_type=\"multi_label_classification\").to(device)\n\n# Функция для обучения одной эпохи\ndef train_one_epoch(epoch, model, train_loader, optimizer, scheduler, criterion):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    loop = tqdm(enumerate(train_loader), total=len(train_loader))\n    loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n    \n    for batch_idx, (text, target) in loop:\n        # Токенизация и подготовка данных\n        inputs = tokenizer(text, \n                           return_tensors=\"pt\", \n                           max_length=128, \n                           truncation=True, \n                           padding=True,\n                           return_attention_mask=True).to(device)\n        \n        input_ids = inputs['input_ids'].to(device)\n        attention_mask = inputs['attention_mask'].to(device)\n        target = target.to(device)\n\n        optimizer.zero_grad()\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        \n        # Логиты находятся в outputs.logits\n        logits = outputs.logits\n\n        # Используем CrossEntropy Loss\n        loss = criterion(logits, target)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * len(text)\n        _, predicted = torch.max(logits, 1)\n\n        correct += (predicted == target).sum().item()\n        total += len(text)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    epoch_accuracy = correct / total\n    \n    scheduler.step(epoch_loss)\n\n    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n    \n    model.save_pretrained(\"/kaggle/working/AlbertForClassification\")\n\n# Пример использования\ntokenizer = AutoTokenizer.from_pretrained('textattack/albert-base-v2-imdb')\n\ntrain_loader = create_dataloader(\"/kaggle/working/dataset/train\", preprocess_text, batch_size, shuffle=True, pin_memory=False)\ntest_loader = create_dataloader(\"/kaggle/working/dataset/test\", preprocess_text, batch_size, shuffle=False, pin_memory=False)\n\n# Оптимизатор и критерий\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-05, weight_decay=1e-2)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=False)\ncriterion = nn.CrossEntropyLoss()\n\nfor i in range(10):\n    # Вызов функции для тренировки одной эпохи\n    train_one_epoch(i, model, train_loader, optimizer, scheduler, criterion)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:50:03.006364Z","iopub.execute_input":"2024-10-16T19:50:03.007319Z","iopub.status.idle":"2024-10-16T20:28:29.571970Z","shell.execute_reply.started":"2024-10-16T19:50:03.007274Z","shell.execute_reply":"2024-10-16T20:28:29.570964Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at textattack/albert-base-v2-imdb and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([8, 768]) in the model instantiated\n- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([8]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nEpoch [1/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 1.4651, Accuracy: 0.4118\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 1.3114, Accuracy: 0.4608\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 1.2168, Accuracy: 0.4968\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 1.1090, Accuracy: 0.5385\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.9767, Accuracy: 0.5936\n","output_type":"stream"},{"name":"stderr","text":"Epoch [6/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 0.8378, Accuracy: 0.6601\n","output_type":"stream"},{"name":"stderr","text":"Epoch [7/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 0.6819, Accuracy: 0.7277\n","output_type":"stream"},{"name":"stderr","text":"Epoch [8/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 0.5578, Accuracy: 0.7808\n","output_type":"stream"},{"name":"stderr","text":"Epoch [9/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 0.4276, Accuracy: 0.8393\n","output_type":"stream"},{"name":"stderr","text":"Epoch [10/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 0.3269, Accuracy: 0.8812\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"/kaggle/working/AlbertForClassification\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10, 20):\n    # Вызов функции для тренировки одной эпохи\n    train_one_epoch(i, model, train_loader, optimizer, scheduler, criterion)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:28:59.322760Z","iopub.execute_input":"2024-10-16T20:28:59.323157Z","iopub.status.idle":"2024-10-16T20:49:47.269858Z","shell.execute_reply.started":"2024-10-16T20:28:59.323122Z","shell.execute_reply":"2024-10-16T20:49:47.268714Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Epoch [11/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11, Loss: 0.2604, Accuracy: 0.9082\n","output_type":"stream"},{"name":"stderr","text":"Epoch [12/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12, Loss: 0.2121, Accuracy: 0.9266\n","output_type":"stream"},{"name":"stderr","text":"Epoch [13/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13, Loss: 0.1886, Accuracy: 0.9335\n","output_type":"stream"},{"name":"stderr","text":"Epoch [14/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14, Loss: 0.1821, Accuracy: 0.9360\n","output_type":"stream"},{"name":"stderr","text":"Epoch [15/10]: 100%|██████████| 1094/1094 [03:50<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15, Loss: 0.1470, Accuracy: 0.9495\n","output_type":"stream"},{"name":"stderr","text":"Epoch [16/10]:  41%|████▏     | 452/1094 [01:35<02:15,  4.74it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Вызов функции для тренировки одной эпохи\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 52\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, train_loader, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 52\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[1;32m     53\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(logits, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m target)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def evaluate(epoch):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        loop = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n        for bathc_idx, (text, target) in loop:\n            target = target.to(device)\n\n            inputs = tokenizer(text, \n                           return_tensors=\"pt\", \n                           max_length=128, \n                           truncation=True, \n                           padding=True,\n                           return_attention_mask=True).to(device)\n            \n            outputs = model(**inputs)\n        \n            # Логиты находятся в outputs.logits\n            logits = outputs.logits\n\n            _, predicted = torch.max(logits, 1)\n\n            correct += (predicted == target).sum().item()\n            total += len(text)\n\n    accuracy = correct / total\n\n    print(f'Test Accuracy: {accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:51:05.923420Z","iopub.execute_input":"2024-10-16T20:51:05.923915Z","iopub.status.idle":"2024-10-16T20:51:05.932160Z","shell.execute_reply.started":"2024-10-16T20:51:05.923875Z","shell.execute_reply":"2024-10-16T20:51:05.931127Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"evaluate(0)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T21:04:40.976238Z","iopub.execute_input":"2024-10-16T21:04:40.976942Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 28%|██▊       | 304/1094 [00:22<00:58, 13.44it/s]","output_type":"stream"}]}]}